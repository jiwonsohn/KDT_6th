{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 모델 클래스\n",
    "- 부모 클래스: nn.Module\n",
    "- 필수 오버라이딩\n",
    "\t* __init__(): 모델 층 구성, 설계\n",
    "\t* forward(): 순방향 학습 진행 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\t\t\t\t\t\t\t\t# 텐서 및 수치 계산 함수 관련 모듈\n",
    "import torch.nn as nn\t\t\t\t\t\t# 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F \t\t\t# 손실, 거래 등 함수 관련 모듈\n",
    "import torch.optim as optimizer \t\t\t# 최적화 기법 관련 모듈\n",
    "from torchinfo import summary\t\t\t\t# 모델 구조 및 정보 관련 모듈\n",
    "\n",
    "from torchmetrics.regression import *\t\t# 회귀 성능 지표 모듈\n",
    "from torchmetrics.classification import *\t# 분류 성능 지표 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [기본] 신경망 클래스\n",
    "\t* 입력층 - 입력 피쳐 개수로 고정\n",
    "\t* 출력층 - 출력 타겟 개수로 고정\n",
    "\t* 은닝층 - 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 설계\n",
    "\t- 데이터셋: 피쳐 4개 & 타겟 1개 , 회귀\n",
    "\t- 입력층  : input: 4,\toutput: 20\t\tAF: ReLU\n",
    "\t- 은닉층  : input: 20,\toutput: 100  \tAF: ReLU\t\t\t 2진\t 다중\n",
    "\t- 출력층  : input: 100,\toutput: 1 \t\tAF: 회귀: X, 분류: (Sigmoid, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치 고정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    # 인스턴스/객체 생성 시 자동호출 메서드\n",
    "    def __init__(self, in_feature):\n",
    "    \n",
    "    # 부모 클래스 생성\n",
    "        super().__init__()\n",
    "    \n",
    "    # 자식클래스 인스턴스 속성 설정\n",
    "        self.input_layer = nn.Linear(in_feature, 20)\t\t# 퍼셉트론 당 w:4개, b:1개  -> 5*20 => 100개 parameter\n",
    "        self.hidden_layer = nn.Linear(20, 100)\t# 퍼셉트론 당 w:20개, b:1개  -> 21*100 => 2100개 parameter\n",
    "        self.output_layer = nn.Linear(100, 1)\t# 퍼셉트론 당 w:100개, b:1개  -> 101*1 => 101개 parameter\n",
    "    \n",
    "\t# Callback func\n",
    "\t# \t\t=> 순반향/전방향 학습 시, 자동호출되는 메서드\n",
    "\t#\t\t=> 시스템에서 호출\n",
    "\t# \t\t=> 전달인자: Train DS\n",
    "    def forward(self, x):\n",
    "        print('calling forward()')\n",
    "\t\t\n",
    "        y = self.input_layer(x)\t\t# 1 Perceptron -> y = x1w1+x2w2+x3w3+x4w4 + b\n",
    "\t\t\t\t\t\t\t\t\t#\t\t\t\t\t\t\t\t\t\t\t--> 20개\n",
    "        y = F.relu(y)\t\t\t\t# 0<= y \t--> 죽은 ReLU 발생 --> leakyReLU로 해결\n",
    "\t\t\n",
    "        y = self.hidden_layer(y)\t# 1 Perceptron -> y = x1w1+ ... + x20w20 + b\n",
    "\t\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t\t\t\t\t--> 100개\n",
    "        y = F.relu(y)\n",
    "\t\t\n",
    "        return self.output_layer(y)\t# 1 Perceptron -> y = x1w1+ ... + x100w100 + b\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력층의 개수가 동적인 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층의 개수가 동적인 모델\n",
    "class MyModel4(nn.Module):\n",
    "    \n",
    "    # 인스턴스/객체 생성 시 자동호출 메서드\n",
    "    def __init__(self,in_features, in_out, hidden_cnt, **h_out):\n",
    "    \n",
    "    # 부모 클래스 생성\n",
    "        super().__init__()\n",
    "    \n",
    "    # 자식클래스 인스턴스 속성 설정\n",
    "    \n",
    "\t\tif hidden_cnt == 0:\t\n",
    "\t\t\tself.input_layer = nn.Linear(in_features, in_out)\t\n",
    "\t\t\tself.output_layer = nn.Linear(in_out, 1)\n",
    "        \n",
    "\t\telif hidden_cnt >0:\n",
    "\t\t\tself.input_layer = nn.Linear(in_features, in_out)\n",
    "\t\t\tself.hidden_yaer = nn.Linear(in_out,h_out)\n",
    "\t\t\tself.output_layer = nn.Linear(h_out, 1)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tprint(f'은닉층 반복횟수는 0또는 양수')\n",
    "    \n",
    "\t# Callback func\n",
    "\t# \t\t=> 순반향/전방향 학습 시, 자동호출되는 메서드\n",
    "\t#\t\t=> 시스템에서 호출\n",
    "\t# \t\t=> 전달인자: Train DS\n",
    "    def forward(self, x, hidden_cnt):\n",
    "        print('calling forward()')\n",
    "        \n",
    "        if hidden_cnt == 0:\n",
    "             y = self.input_layer(x)\n",
    "\t\t\t \n",
    "\t\t\n",
    "        y = self.input_layer(x)\t\t# 1 Perceptron -> y = x1w1+x2w2+x3w3+x4w4 + b\n",
    "\t\t\t\t\t\t\t\t\t#\t\t\t\t\t\t\t\t\t\t\t--> 20개\n",
    "        y = F.relu(y)\t\t\t\t# 0<= y \t--> 죽은 ReLU 발생 --> leakyReLU로 해결\n",
    "\t\t\n",
    "        y = self.hidden_layer(y)\t# 1 Perceptron -> y = x1w1+ ... + x20w20 + b\n",
    "\t\t\t\t\t\t\t\t\t# \t\t\t\t\t\t\t\t\t\t\t--> 100개\n",
    "        y = F.relu(y)\n",
    "\t\t\n",
    "        return self.output_layer(y)\t# 1 Perceptron -> y = x1w1+ ... + x100w100 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "m1 = MyModel(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in m1.parameters(): print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in m1.named_parameters(): print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling forward()\n",
      "tensor([[-0.1395],\n",
      "        [-0.1858]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행 ==> 모델인스턴스명(데이터)\n",
    "\n",
    "# 임의의 데이터\n",
    "dataTS = torch.FloatTensor( [[1,3,5,7], [2,4,6,8]])\n",
    "targetTS = torch.FloatTensor( [[4],[5]] )\n",
    "\n",
    "# 학습\n",
    "pre_y = m1(dataTS)\n",
    "\n",
    "print(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
