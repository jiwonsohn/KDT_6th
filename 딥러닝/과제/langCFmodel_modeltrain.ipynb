{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알파벳 빈도수 기반 언어 식별 모델\n",
    "* 데이터셋: lang.zip\n",
    "* 피쳐/속성: 알파벳 26개\n",
    "* 타겟/라벨: class 칼럼 (클래스 4개)\n",
    "\t\t* -> 0: en, 1:fr, 2:id, 3:tl\n",
    "* 학습방법:\t지도학습 >> 분류 >> 다중분류 (클래스: 4개)\n",
    "* 알고리즘: 딥러닝 층: 3개 (입력층, 은닉층:1개, 출력층)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 관련 모듈\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim \n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torchinfo import summary\n",
    "\n",
    "# 데이터 전처리 & 시각화 관련 모듈\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] 데이터 로드 & 전처리 & 타겟/피쳐 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          a         b         c         d         e         f         g  \\\n",
      "0  0.075952  0.012840  0.045702  0.046137  0.105332  0.015669  0.019151   \n",
      "1  0.084178  0.019912  0.030404  0.038870  0.136998  0.017408  0.031239   \n",
      "2  0.071646  0.012172  0.045643  0.032642  0.120055  0.014661  0.025173   \n",
      "\n",
      "          h         i         j  ...         r         s         t         u  \\\n",
      "0  0.043743  0.073993  0.001741  ...  0.077693  0.061371  0.080522  0.025898   \n",
      "1  0.027423  0.075355  0.002623  ...  0.090140  0.071659  0.077739  0.030643   \n",
      "2  0.023513  0.094606  0.002490  ...  0.053942  0.087967  0.081051  0.029046   \n",
      "\n",
      "          v         w         x         y         z  class  \n",
      "0  0.009793  0.014146  0.000653  0.020022  0.000435     en  \n",
      "1  0.013712  0.013950  0.002027  0.010731  0.000596     en  \n",
      "2  0.018811  0.011895  0.000553  0.017981  0.000553     en  \n",
      "\n",
      "[3 rows x 27 columns]\n",
      "\n",
      "          a         b         c         d         e         f         g  \\\n",
      "0  0.067823  0.013459  0.034328  0.048817  0.116114  0.020014  0.016002   \n",
      "1  0.080283  0.016174  0.035350  0.038342  0.129865  0.016704  0.018950   \n",
      "2  0.056764  0.012008  0.035835  0.049876  0.127155  0.013476  0.008620   \n",
      "\n",
      "          h         i         j  ...         r         s         t         u  \\\n",
      "0  0.022798  0.076920  0.002411  ...  0.070124  0.079550  0.075122  0.025910   \n",
      "1  0.042697  0.073986  0.004463  ...  0.066227  0.063599  0.078880  0.027631   \n",
      "2  0.007303  0.086050  0.002786  ...  0.067304  0.090078  0.068433  0.042912   \n",
      "\n",
      "          v         w         x         y         z  class  \n",
      "0  0.014775  0.036103  0.005634  0.013087  0.000416     en  \n",
      "1  0.013026  0.014880  0.002119  0.013300  0.001491     en  \n",
      "2  0.013852  0.028909  0.009298  0.005157  0.000414     fr  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "path_train = \"../language/train_feature.csv\"\n",
    "path_test  = \"../language/test_feature.csv\"\n",
    "\n",
    "trainDF = pd.read_csv(path_train)\n",
    "testDF = pd.read_csv(path_test)\n",
    "\n",
    "print(trainDF.head(3))\n",
    "print()\n",
    "print(testDF.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'fr', 'id', 'tl']\n",
      "{'en': 0, 'fr': 1, 'id': 2, 'tl': 3}\n",
      "          a         b         c         d         e         f         g  \\\n",
      "0  0.075952  0.012840  0.045702  0.046137  0.105332  0.015669  0.019151   \n",
      "1  0.084178  0.019912  0.030404  0.038870  0.136998  0.017408  0.031239   \n",
      "2  0.071646  0.012172  0.045643  0.032642  0.120055  0.014661  0.025173   \n",
      "\n",
      "          h         i         j  ...         s         t         u         v  \\\n",
      "0  0.043743  0.073993  0.001741  ...  0.061371  0.080522  0.025898  0.009793   \n",
      "1  0.027423  0.075355  0.002623  ...  0.071659  0.077739  0.030643  0.013712   \n",
      "2  0.023513  0.094606  0.002490  ...  0.087967  0.081051  0.029046  0.018811   \n",
      "\n",
      "          w         x         y         z  class  class_encd  \n",
      "0  0.014146  0.000653  0.020022  0.000435     en           0  \n",
      "1  0.013950  0.002027  0.010731  0.000596     en           0  \n",
      "2  0.011895  0.000553  0.017981  0.000553     en           0  \n",
      "\n",
      "[3 rows x 28 columns]\n",
      "\n",
      "          a         b         c         d         e         f         g  \\\n",
      "0  0.067823  0.013459  0.034328  0.048817  0.116114  0.020014  0.016002   \n",
      "1  0.080283  0.016174  0.035350  0.038342  0.129865  0.016704  0.018950   \n",
      "2  0.056764  0.012008  0.035835  0.049876  0.127155  0.013476  0.008620   \n",
      "\n",
      "          h         i         j  ...         s         t         u         v  \\\n",
      "0  0.022798  0.076920  0.002411  ...  0.079550  0.075122  0.025910  0.014775   \n",
      "1  0.042697  0.073986  0.004463  ...  0.063599  0.078880  0.027631  0.013026   \n",
      "2  0.007303  0.086050  0.002786  ...  0.090078  0.068433  0.042912  0.013852   \n",
      "\n",
      "          w         x         y         z  class  class_encd  \n",
      "0  0.036103  0.005634  0.013087  0.000416     en           0  \n",
      "1  0.014880  0.002119  0.013300  0.001491     en           0  \n",
      "2  0.028909  0.009298  0.005157  0.000414     fr           1  \n",
      "\n",
      "[3 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# 'class' 칼럼 인코딩\n",
    "# 0:en, 1:fr, 2:id, 3:tl\n",
    "\n",
    "lang_class = trainDF['class'].unique().tolist()\n",
    "print(lang_class)\n",
    "\n",
    "labels = dict(zip(lang_class, range(len(lang_class))))\n",
    "print(labels)\n",
    "\n",
    "# add encoded class column to trainDF/testDF\n",
    "trainDF['class_encd'] = trainDF['class'].replace(labels)\n",
    "print(trainDF.head(3))\n",
    "testDF['class_encd'] = testDF['class'].replace(labels)\n",
    "print()\n",
    "print(testDF.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 26) (20, 1)\n",
      "\n",
      "(15, 26)\n",
      "(15, 1)\n",
      "\n",
      "(5, 26)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "# 타겟 & 피쳐 분리\n",
    "targetDF = trainDF[[trainDF.columns[-1]]]\n",
    "featureDF = trainDF[trainDF.columns[:-2]]\n",
    "\n",
    "print(featureDF.shape, targetDF.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(featureDF, targetDF,\n",
    "                                                  stratify=targetDF,\n",
    "                                                  random_state=10)\n",
    "print()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print()\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_encd\n",
      "0             4\n",
      "2             4\n",
      "3             4\n",
      "1             3\n",
      "Name: count, dtype: int64\n",
      "class_encd\n",
      "1             2\n",
      "0             1\n",
      "2             1\n",
      "3             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2] 모델 클래스 설계 및 정의\n",
    "- 클래스목적 : lang data 학습 및 언어 클래스 추론 목적\n",
    "- 클래스이름 : LangMCFModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개__변수 : 층별 입출력 개수 고정 -> 필요 X\n",
    "- 속성__필드 : \n",
    "- 기능__역할 : __init__() : 모델 구조 설정 ,  forward() : 순방향 학습 <= 오바라이딩(overriding)\n",
    "- 클래스구조 \n",
    "    * 입력층 : 입력  26개(피쳐)      출력    50개 AF: ReLU\n",
    "    * 은닉층 : 입력 50개            출력    10개  AF: ReLU\n",
    "    * 출력층 : 입력 10개            출력    4개  AF: X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangMCFModel(nn.Module):\n",
    "    \n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.in_layer = nn.Linear(26, 50)\n",
    "\t\tself.hd_layer = nn.Linear(50, 10)\n",
    "\t\tself.ot_layer = nn.Linear(10, 4)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\n",
    "\t\ty = F.relu(self.in_layer(x))\n",
    "\t\ty = F.relu(self.hd_layer(y))\n",
    "\t\treturn self.ot_layer(y)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangMCFModel(\n",
      "  (in_layer): Linear(in_features=26, out_features=50, bias=True)\n",
      "  (hd_layer): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (ot_layer): Linear(in_features=10, out_features=4, bias=True)\n",
      ")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LangMCFModel                             [20000, 4]                --\n",
       "├─Linear: 1-1                            [20000, 50]               1,350\n",
       "├─Linear: 1-2                            [20000, 10]               510\n",
       "├─Linear: 1-3                            [20000, 4]                44\n",
       "==========================================================================================\n",
       "Total params: 1,904\n",
       "Trainable params: 1,904\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 38.08\n",
       "==========================================================================================\n",
       "Input size (MB): 2.08\n",
       "Forward/backward pass size (MB): 10.24\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 12.33\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [테스트] 사용자 정의 모델 확인\n",
    "model = LangMCFModel()\n",
    "\n",
    "print(model)\n",
    "print()\n",
    "summary(model, input_size=(20000, 26))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3] 데이터셋 클래스 설계 및 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangDataset(Dataset):\n",
    "    \n",
    "\tdef __init__(self, featureDF, targetDF):\n",
    "\n",
    "\t\tself.featureDF = featureDF\n",
    "\t\tself.targetDF  = targetDF\n",
    "\t\tself.n_rows = featureDF.shape[0]\n",
    "\t\tself.n_features = featureDF.shape[1]\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.n_rows\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\n",
    "\t\tfeatureTS = torch.FloatTensor(self.featureDF.iloc[idx].values)\n",
    "\t\ttargetTS = torch.FloatTensor(self.targetDF.iloc[idx].values)\n",
    "\n",
    "\t\treturn featureTS, targetTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 26]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# [테스트] 데이터셋 인스턴스 생성\n",
    "\n",
    "langDS = LangDataset(featureDF, targetDF)\n",
    "\n",
    "langDL = DataLoader(langDS)\n",
    "\n",
    "for feature, label in langDL:\n",
    "    print(feature.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4] 학습준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "BACTCH_SIZE = 5\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 26)  (5, 26)\n",
      "(15, 1)  (5, 1)\n",
      "class_encd\n",
      "0             4\n",
      "2             4\n",
      "3             4\n",
      "1             3\n",
      "Name: count, dtype: int64 class_encd\n",
      "1             2\n",
      "0             1\n",
      "2             1\n",
      "3             1\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습용, 검증용, 테스트용 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(featureDF, targetDF,\n",
    "                                                  stratify=targetDF,\n",
    "                                                  random_state=10)\n",
    "print(f'{X_train.shape}  {X_val.shape}')\n",
    "print(f'{y_train.shape}  {y_val.shape}')\n",
    "print(f'{y_train.value_counts()} {y_val.value_counts()}')\n",
    "print()\n",
    "\n",
    "# 데이터셋 분리\n",
    "trainDS = LangDataset(X_train, y_train)\n",
    "validDS = LangDataset(X_val, y_val)\n",
    "testDS  = LangDataset(testDF[testDF.columns[:-2]], testDF[[testDF.columns[-1]]])\n",
    "\n",
    "# 학습용 데이터로더 인스턴스\n",
    "trainDL = DataLoader(trainDS, batch_size = BACTCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스\n",
    "crossLoss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [5] 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > 모델 저장 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = r'C:/Users/KDP-43/Desktop/딥러닝/0919/models/lang/'\n",
    "\n",
    "SAVE_MODEL = 'model_all.pth'\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- > 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_CNT => 3\n",
      "torch.Size([5, 4]) torch.Size([5])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# 손실\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     loss_val\u001b[38;5;241m=\u001b[39mcrossLoss(pre_val, val_targetTS\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m---> 47\u001b[0m     score_val\u001b[38;5;241m=\u001b[39m\u001b[43mMulticlassF1Score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_targetTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 에포크 당 손실값과 성능평가값 저장    \u001b[39;00m\n\u001b[0;32m     50\u001b[0m LOSS_HISTORY[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss_total\u001b[38;5;241m/\u001b[39mCNT)\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torchmetrics\\metric.py:312\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torchmetrics\\metric.py:381\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torchmetrics\\metric.py:483\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torchmetrics\\classification\\stat_scores.py:339\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 339\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[0;32m    343\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[0;32m    344\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[0;32m    345\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\KDP-43\\anaconda3\\envs\\torch_38\\lib\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:283\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[1;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `preds` have one dimension more than `target`, `preds` should be a float tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m num_classes:\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `preds` have one dimension more than `target`, `preds.shape[1]` should be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m equal to number of classes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     )\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `preds` have one dimension more than `target`, the shape of `preds` should be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (N, C, ...), and the shape of `target` should be (N, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: If `preds` have one dimension more than `target`, `preds.shape[1]` should be equal to number of classes."
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인 손실값과 성능평가값 저장 필요\n",
    "LOSS_HISTORY, SCORE_HISTORY=[[],[]], [[],[]]\n",
    "CNT=len(trainDL)\n",
    "print(f'BATCH_CNT => {CNT}')\n",
    "\n",
    "## 학습 모니터링 설정 -------------------------------------\n",
    "BREAK_CNT = 0\n",
    "LIMIT_VALUE = 30\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    # 학습 모드로 모델 설정\n",
    "    model.train()\n",
    "    \n",
    "    # 배치 크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total, score_total=0,0\n",
    "    for featureTS, targetTS in trainDL:\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "        \n",
    "        # 손실 계산 : nn.CrossEntropyLoss 요구사항 : 정답/타겟은 0D 또는 1D,  타입은 long\n",
    "        loss=crossLoss(pre_y, targetTS.reshape(-1).long())\n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        # 성능평가 계산\n",
    "        score=MulticlassF1Score(num_classes=4)(pre_y, targetTS.reshape(-1))\n",
    "        score_total += score.item()\n",
    "        \n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # 에포크 당 검증기능\n",
    "    # 모델 검증 모드 설정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 검증 데이터셋\n",
    "        val_featrueTS=torch.FloatTensor(validDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(validDS.targetDF.values)\n",
    "        \n",
    "        # 추론/평가\n",
    "        pre_val=model(val_featrueTS)\n",
    "        print(pre_val.shape, val_targetTS.reshape(-1).shape)\n",
    "        \n",
    "        # 손실\n",
    "        loss_val=crossLoss(pre_val, val_targetTS.reshape(-1).long())\n",
    "        score_val=MulticlassF1Score(num_classes=3)(pre_val, val_targetTS.reshape(-1))\n",
    "\n",
    "    # 에포크 당 손실값과 성능평가값 저장    \n",
    "    LOSS_HISTORY[0].append(loss_total/CNT)\n",
    "    SCORE_HISTORY[0].append(score_total/CNT)\n",
    "    \n",
    "    LOSS_HISTORY[1].append(loss_val)\n",
    "    SCORE_HISTORY[1].append(score_val)\n",
    "    \n",
    "    print(f'[{epoch}/{EPOCH}]\\n- [TRAIN] LOSS : {LOSS_HISTORY[0][-1]} SCORE : {SCORE_HISTORY[0][-1]}')\n",
    "    print(f'- [VALID] LOSS : {LOSS_HISTORY[1][-1]} SCORE : {SCORE_HISTORY[1][-1]}')\n",
    "\n",
    "\t# 모델 모니터링---------------------------------------------------\n",
    "    # 검증 DS 기준\n",
    "    \n",
    "    if len(SCORE_HISTORY[1]) > 1:\n",
    "        if SCORE_HISTORY[1][-1] <= SCORE_HISTORY[1][-2]:\n",
    "            BREAK_CNT += 1\n",
    "            \n",
    "\t# 좋은 성능 학습 모델 & 파라미터 저장\n",
    "    SAVE_FILE = f'Model_train_wb_{epoch}_{score_val:.4f}.pth'\n",
    "    \n",
    "    if len(SCORE_HISTORY[1]) ==1:\n",
    "        torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "        torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        torch.save(model.state_dict(), SAVE_PATH+SAVE_FILE)\n",
    "        torch.save(model, SAVE_PATH+SAVE_MODEL)\n",
    "        \n",
    "\n",
    "\t# 학습 중단 여부 결정\n",
    "    if BREAK_CNT > LIMIT_VALUE:\n",
    "        print(f\"score 개선 변화가 없어 {epoch} EPOCH에서 학습을 중단.\")\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
