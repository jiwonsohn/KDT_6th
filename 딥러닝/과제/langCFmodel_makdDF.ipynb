{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알파벳 빈도수 기반 언어 식별 모델\n",
    "* 데이터셋: lang.zip\n",
    "* 피쳐/속성: 알파벳 26개\n",
    "* 타겟/라벨: class 변수 1개 4개 (영어, 불어, 터키어, 말레이시아어)\n",
    "* 학습방법:\t지도학습 >> 분류 >> 다중분류 (클래스: 4개)\n",
    "* 알고리즘: 딥러닝 층: 3개 (입력층, 은닉층:1개, 출력층)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point\n",
    "* 알파벳(26개) 제외 문자 drop\n",
    "* 대소문자 통일\n",
    "* **각 파일마다 전체 알파벳 개수가 다름\t=> 각 파일에 대해 전체 알파벳 빈도수 합으로 나누어 빈도율을 통일해야!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 & 시각화 관련 모듈\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *.txt 파일 오픈 & 모든 알파벳 갯수 저장 Dict 반환 함수\n",
    "\n",
    "def read_count(f_name, alphabets, data_path):\n",
    "\n",
    "    if not os.path.exists(data_path+f_name):\n",
    "        print(f'{f_name}이 없습니다.')\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        with open(data_path+f_name, \"r\") as f:\n",
    "            print(f,data_path+f_name, os.path.exists(data_path+f_name))\n",
    "\n",
    "\t\t\t# 모든 문자 소문자 통일\n",
    "            data = f.read().lower()\n",
    "\n",
    "        \n",
    "\t\t\t# 알파벳 아닌 문자들 제거\n",
    "            print(\"알파벳 전처리 전: \",len(data))\n",
    "            for ch in data:\n",
    "                if ord('a')> ord(ch) or ord(ch) > ord('z'):\n",
    "\t\t\t\t# if not ord('a')> ch or ch > ord('z'):\t\n",
    "                    data = data.replace(ch,'')\n",
    "            print(\"알파벳 전처리 후: \", len(data))\n",
    "            \n",
    "        total_len = len(data)\n",
    "\n",
    "\t\t## 각 txt 파일 내 모든 알파벳 갯수 저장 dict 생성\n",
    "\t\t# {'a': ###, ..., 'z': ###}\n",
    "        # data_count_dict = {}\n",
    "\n",
    "        # for chrcter in alphabets:\n",
    "        #     data_count_dict[chrcter] = data.count(chrcter)\n",
    "\n",
    "\t\t## 알파벳 유니코드 값 기준 counting Ver.-----------------------------------\n",
    "        cnt_list = [0*len(alphabets)]\n",
    "        \n",
    "        a_z = dict(zip(alphabets,cnt_list))\n",
    "        \n",
    "        for _ in range( ord('a'), ord('z')+1):\n",
    "             cnt = data.count(chr(_))\n",
    "             a_z[chr(_)] = cnt/total_len\n",
    "\n",
    "\t\t# Counter Ver.------------------------------------------------------------\n",
    "        # count_dict = Counter(data)\t\t\t# 알파벳 별 빈도 수 딕셔너리 반환 \n",
    "\t\t# \t\t\t\t\t\t\t\t\t# 알파벳 정렬 X!\n",
    "\n",
    "\t\t# # 전체 개수로 각 알파벳 빈도수 나누기\n",
    "        # count_dict_normalized = {key: (lambda val: val/total_len)(val) for key, val in count_dict.items()}\n",
    "        \n",
    "\t\t# a-z 알파벳 순 dict 정렬\n",
    "        # \t\t-> DF 생성 후 칼럼명 기준 정렬!\n",
    "        \n",
    "    return a_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list: ['en-1.txt', 'en-2.txt', 'en-3.txt', 'en-4.txt', 'en-5.txt', 'fr-10.txt', 'fr-6.txt', 'fr-7.txt', 'fr-8.txt', 'fr-9.txt', 'id-11.txt', 'id-12.txt', 'id-13.txt', 'id-14.txt', 'id-15.txt', 'tl-16.txt', 'tl-17.txt', 'tl-18.txt', 'tl-19.txt', 'tl-20.txt']\n"
     ]
    }
   ],
   "source": [
    "path = \"../language/train/\"\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "print (\"file_list: {}\".format(file_list))\n",
    "\n",
    "\n",
    "alphabets=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "lang_class_list = []\n",
    "alltxt_data_count = []\n",
    "\n",
    "for file1 in file_list:\n",
    "    \n",
    "    lang_class_list.append(file1[:2])\t\t\t\t# en, fr, id, tl 추출\n",
    "    \n",
    "    alltxt_data_count.append( read_count(file1, alphabets, data_path=path) )\n",
    "        \n",
    "\t\n",
    "# DF 생성\n",
    "rawDF = pd.DataFrame(alltxt_data_count)\n",
    "rawDF.head(10)\n",
    "\n",
    "print(rawDF.isna().sum())\n",
    "\n",
    "# 언어클래스 칼럼 생성\n",
    "rawDF['class'] = lang_class_list\n",
    "rawDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_list: ['en-1.txt', 'en-2.txt', 'fr-3.txt', 'fr-4.txt', 'id-5.txt', 'id-6.txt', 'tl-7.txt', 'tl-8.txt']\n",
      "<_io.TextIOWrapper name='../language/test/en-1.txt' mode='r' encoding='UTF-8'> ../language/test/en-1.txt True\n",
      "알파벳 전처리 전:  61410\n",
      "알파벳 전처리 후:  45619\n",
      "<_io.TextIOWrapper name='../language/test/en-2.txt' mode='r' encoding='UTF-8'> ../language/test/en-2.txt True\n",
      "알파벳 전처리 전:  141276\n",
      "알파벳 전처리 후:  101952\n",
      "<_io.TextIOWrapper name='../language/test/fr-3.txt' mode='r' encoding='UTF-8'> ../language/test/fr-3.txt True\n",
      "알파벳 전처리 전:  36833\n",
      "알파벳 전처리 후:  26566\n",
      "<_io.TextIOWrapper name='../language/test/fr-4.txt' mode='r' encoding='UTF-8'> ../language/test/fr-4.txt True\n",
      "알파벳 전처리 전:  65045\n",
      "알파벳 전처리 후:  45301\n",
      "<_io.TextIOWrapper name='../language/test/id-5.txt' mode='r' encoding='UTF-8'> ../language/test/id-5.txt True\n",
      "알파벳 전처리 전:  8455\n",
      "알파벳 전처리 후:  6154\n",
      "<_io.TextIOWrapper name='../language/test/id-6.txt' mode='r' encoding='UTF-8'> ../language/test/id-6.txt True\n",
      "알파벳 전처리 전:  33524\n",
      "알파벳 전처리 후:  25641\n",
      "<_io.TextIOWrapper name='../language/test/tl-7.txt' mode='r' encoding='UTF-8'> ../language/test/tl-7.txt True\n",
      "알파벳 전처리 전:  34739\n",
      "알파벳 전처리 후:  26235\n",
      "<_io.TextIOWrapper name='../language/test/tl-8.txt' mode='r' encoding='UTF-8'> ../language/test/tl-8.txt True\n",
      "알파벳 전처리 전:  2124\n",
      "알파벳 전처리 후:  1652\n",
      "a        0\n",
      "b        0\n",
      "c        0\n",
      "d        0\n",
      "e        0\n",
      "f        0\n",
      "g        0\n",
      "h        0\n",
      "i        0\n",
      "j        0\n",
      "k        0\n",
      "l        0\n",
      "m        0\n",
      "n        0\n",
      "o        0\n",
      "p        0\n",
      "q        0\n",
      "r        0\n",
      "s        0\n",
      "t        0\n",
      "u        0\n",
      "v        0\n",
      "w        0\n",
      "x        0\n",
      "y        0\n",
      "z        0\n",
      "class    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>...</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>0.034328</td>\n",
       "      <td>0.048817</td>\n",
       "      <td>0.116114</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.076920</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070124</td>\n",
       "      <td>0.079550</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>0.025910</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.036103</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080283</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>0.035350</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>0.129865</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.042697</td>\n",
       "      <td>0.073986</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066227</td>\n",
       "      <td>0.063599</td>\n",
       "      <td>0.078880</td>\n",
       "      <td>0.027631</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.035835</td>\n",
       "      <td>0.049876</td>\n",
       "      <td>0.127155</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.086050</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067304</td>\n",
       "      <td>0.090078</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e         f         g  \\\n",
       "0  0.067823  0.013459  0.034328  0.048817  0.116114  0.020014  0.016002   \n",
       "1  0.080283  0.016174  0.035350  0.038342  0.129865  0.016704  0.018950   \n",
       "2  0.056764  0.012008  0.035835  0.049876  0.127155  0.013476  0.008620   \n",
       "\n",
       "          h         i         j  ...         r         s         t         u  \\\n",
       "0  0.022798  0.076920  0.002411  ...  0.070124  0.079550  0.075122  0.025910   \n",
       "1  0.042697  0.073986  0.004463  ...  0.066227  0.063599  0.078880  0.027631   \n",
       "2  0.007303  0.086050  0.002786  ...  0.067304  0.090078  0.068433  0.042912   \n",
       "\n",
       "          v         w         x         y         z  class  \n",
       "0  0.014775  0.036103  0.005634  0.013087  0.000416     en  \n",
       "1  0.013026  0.014880  0.002119  0.013300  0.001491     en  \n",
       "2  0.013852  0.028909  0.009298  0.005157  0.000414     fr  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST_DF\n",
    "path = \"../language/test/\"\n",
    "file_list = os.listdir(path)\n",
    "\n",
    "print (\"file_list: {}\".format(file_list))\n",
    "\n",
    "\n",
    "alphabets=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "lang_class_list = []\n",
    "alltxt_data_count = []\n",
    "\n",
    "for file1 in file_list:\n",
    "    \n",
    "    lang_class_list.append(file1[:2])\t\t\t\t# en, fr, id, tl 추출\n",
    "    \n",
    "    alltxt_data_count.append( read_count(file1, alphabets, data_path=path) )\n",
    "        \n",
    "\t\n",
    "# DF 생성\n",
    "raw_test_DF = pd.DataFrame(alltxt_data_count)\n",
    "rawDF.head(10)\n",
    "\n",
    "print(rawDF.isna().sum())\n",
    "\n",
    "# 언어클래스 칼럼 생성\n",
    "raw_test_DF['class'] = lang_class_list\n",
    "raw_test_DF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 저장\n",
    "SAVE_PATH = '../language/'\n",
    "rawDF.to_csv(SAVE_PATH+'train_feature.csv', index=False)\n",
    "raw_test_DF.to_csv(SAVE_PATH+'test_feature.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\KDP-43\\\\Desktop\\\\딥러닝\\\\과제'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
